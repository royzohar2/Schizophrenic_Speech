{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import ttest_ind\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "yap_df = pd.read_csv(\"/Users/seanlavi/dev/Schizophrenic_Speech/data/morphological_yap_features.csv\", index_col = False)\n",
    "yap_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "yap_df = yap_df[[\"attention_scores_per_sentence\", \"person\", \"label\", \"question\"]]\n",
    "yap_df = yap_df[yap_df[\"attention_scores_per_sentence\"] != \"[]\"]\n",
    "yap_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "yap_df['attention_scores_per_sentence'] = yap_df['attention_scores_per_sentence'].apply(eval)\n",
    "\n",
    "# Compute mean attention score per row\n",
    "yap_df['mean_attention_score'] = yap_df['attention_scores_per_sentence'].apply(np.mean)\n",
    "yap_df[\"var_attention_score\"] = yap_df['attention_scores_per_sentence'].apply(np.var)\n",
    "yap_df['attention_min'] = yap_df['attention_scores_per_sentence'].apply(np.min)\n",
    "\n",
    "def calculate_weighted_average(scores):\n",
    "    weights = np.exp(np.arange(1, len(scores) + 1))  # Exponential weights\n",
    "    weighted_avg = np.average(scores, weights=weights)\n",
    "    return weighted_avg\n",
    "\n",
    "\n",
    "yap_df['weighted_avg_attention'] = yap_df['attention_scores_per_sentence'].apply(calculate_weighted_average)\n",
    "yap_df.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Calculate the size of each list in 'attention_scores_per_sentence'\n",
    "yap_df['list_size'] = yap_df['attention_scores_per_sentence'].apply(len)\n",
    "\n",
    "# Plot histogram of the sizes of the lists\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(yap_df['list_size'], bins=30, color='skyblue', edgecolor='black')\n",
    "plt.title('Histogram of List Sizes in attention_scores_per_sentence')\n",
    "plt.xlabel('Size of List')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(axis='y', alpha=0.75)\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Additional grid for histograms\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "    # Histogram\n",
    "    sns.histplot(yap_df[metric], kde=True, ax=axes[i])\n",
    "    axes[i].set_title(f'Histogram of {metric}')\n",
    "    axes[i].set_xlabel(metric)\n",
    "    axes[i].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# Define the metrics to plot\n",
    "metrics = ['mean_attention_score', 'var_attention_score', 'attention_min', 'weighted_avg_attention']\n",
    "\n",
    "# Set up the grid for plotting\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Loop through the metrics and create a boxplot and histogram for each\n",
    "for i, metric in enumerate(metrics):\n",
    "    # Boxplot\n",
    "    sns.boxplot(x='label', y=metric, data=yap_df, ax=axes[i])\n",
    "    axes[i].set_title(f'Boxplot of {metric}')\n",
    "    axes[i].set_xlabel('Label')\n",
    "    axes[i].set_ylabel(metric)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "regular_group = yap_df[yap_df['label'] == 0]\n",
    "schizo_group = yap_df[yap_df['label'] == 1]\n",
    "\n",
    "# Create subplots\n",
    "fig, axes = plt.subplots(len(metrics), 1, figsize=(10, 6 * len(metrics)))\n",
    "\n",
    "# Plot histograms for each metric\n",
    "for i, metric in enumerate(metrics):\n",
    "    sns.histplot(regular_group[metric], color='blue', label='Regular', kde=True, ax=axes[i])\n",
    "    sns.histplot(schizo_group[metric], color='red', label='Schizophrenic', kde=True, ax=axes[i])\n",
    "    axes[i].set_title(f'Distribution of {metric.replace(\"_\", \" \").title()}')\n",
    "    axes[i].set_xlabel(metric.replace(\"_\", \" \").title())\n",
    "    axes[i].set_ylabel('Frequency')\n",
    "    axes[i].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# Define a function to perform t-tests and print results for each feature\n",
    "def perform_t_tests(features, schizo_group, regular_group):\n",
    "    for feature in features:\n",
    "        t_stat, p_value = ttest_ind(schizo_group[feature], regular_group[feature])\n",
    "\n",
    "        print(f\"\\nT-Test Results for {feature}:\")\n",
    "        print(f\"T-statistic: {t_stat:.4f}, P-value: {p_value:.4f}\")\n",
    "\n",
    "        # Interpret results\n",
    "        if p_value < 0.05:\n",
    "            print(f\"There is a statistically significant difference in {feature} between schizophrenic and regular persons.\")\n",
    "        else:\n",
    "            print(f\"There is no statistically significant difference in {feature} between schizophrenic and regular persons.\")\n",
    "\n",
    "# List of features to test\n",
    "features_to_test = ['mean_attention_score', 'attention_min', 'weighted_avg_attention'] # var is not noramlly distributed, invalid for t-test\n",
    "\n",
    "# Perform t-tests for all features\n",
    "perform_t_tests(features_to_test, schizo_group, regular_group)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Calculate the correlation matrix for the relevant features\n",
    "corr_matrix = yap_df[['mean_attention_score', 'var_attention_score', 'attention_min', 'weighted_avg_attention', 'label']].corr()\n",
    "\n",
    "# Plot the heatmap of the correlation matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title('Correlation Matrix of Attention Score Features')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Select features and target variable\n",
    "features = ['mean_attention_score', 'var_attention_score', 'attention_min', 'weighted_avg_attention']\n",
    "X = yap_df[features]\n",
    "y = yap_df['label']  # Assuming 'label' is your target column\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the logistic regression model\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Calculate AUC-ROC\n",
    "y_pred_prob = logreg.predict_proba(X_test)[:, 1]\n",
    "roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
    "print(f\"AUC-ROC: {roc_auc:.4f}\")\n",
    "\n",
    "# Feature importance (coefficients)\n",
    "feature_importance = pd.DataFrame({'Feature': features, 'Coefficient': logreg.coef_[0]})\n",
    "feature_importance['Abs_Coefficient'] = feature_importance['Coefficient'].abs()\n",
    "feature_importance = feature_importance.sort_values(by='Abs_Coefficient', ascending=False)\n",
    "\n",
    "print(\"\\nFeature Importance based on Coefficients:\")\n",
    "print(feature_importance)\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(feature_importance['Feature'], feature_importance['Abs_Coefficient'])\n",
    "plt.title('Feature Importance based on Logistic Regression Coefficients')\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Absolute Coefficient Value')\n",
    "plt.show()\n",
    "\n",
    "# Check for multicollinearity using Variance Inflation Factor (VIF)\n",
    "X_with_constant = sm.add_constant(X)\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"Feature\"] = X_with_constant.columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X_with_constant.values, i) for i in range(X_with_constant.shape[1])]\n",
    "\n",
    "print(\"\\nVariance Inflation Factor (VIF) for Each Feature:\")\n",
    "print(vif_data)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}